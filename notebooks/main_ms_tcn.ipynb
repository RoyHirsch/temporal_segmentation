{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865382ff-dc6d-4741-a55c-055b039b713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e78f219-846a-42e5-aea4-dba723d9fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ee9d305-68e2-4531-bc99-7d3d082116d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1]: epoch loss = 10.872463,   acc = 0.121365\n",
      "[epoch 2]: epoch loss = 8.909709,   acc = 0.210815\n",
      "[epoch 3]: epoch loss = 7.218812,   acc = 0.307925\n",
      "[epoch 4]: epoch loss = 5.980003,   acc = 0.455759\n",
      "[epoch 5]: epoch loss = 6.033541,   acc = 0.494258\n",
      "[epoch 6]: epoch loss = 5.080211,   acc = 0.565034\n",
      "[epoch 7]: epoch loss = 4.719374,   acc = 0.625572\n",
      "[epoch 8]: epoch loss = 3.997017,   acc = 0.688736\n",
      "[epoch 9]: epoch loss = 3.771072,   acc = 0.731965\n",
      "[epoch 10]: epoch loss = 3.355755,   acc = 0.787459\n",
      "[epoch 11]: epoch loss = 3.267400,   acc = 0.803547\n",
      "[epoch 12]: epoch loss = 3.103073,   acc = 0.810846\n",
      "[epoch 13]: epoch loss = 3.446028,   acc = 0.789883\n",
      "[epoch 14]: epoch loss = 2.954061,   acc = 0.818759\n",
      "[epoch 15]: epoch loss = 2.779363,   acc = 0.840860\n",
      "[epoch 16]: epoch loss = 2.719848,   acc = 0.840498\n",
      "[epoch 17]: epoch loss = 2.326653,   acc = 0.880091\n",
      "[epoch 18]: epoch loss = 2.319199,   acc = 0.881853\n",
      "[epoch 19]: epoch loss = 2.239134,   acc = 0.885563\n",
      "[epoch 20]: epoch loss = 2.129269,   acc = 0.891549\n",
      "[epoch 21]: epoch loss = 2.003649,   acc = 0.900265\n",
      "[epoch 22]: epoch loss = 2.340797,   acc = 0.867687\n",
      "[epoch 23]: epoch loss = 3.191076,   acc = 0.818633\n",
      "[epoch 24]: epoch loss = 2.564605,   acc = 0.858104\n",
      "[epoch 25]: epoch loss = 2.610322,   acc = 0.850914\n",
      "[epoch 26]: epoch loss = 2.057559,   acc = 0.900117\n",
      "[epoch 27]: epoch loss = 1.887852,   acc = 0.908771\n",
      "[epoch 28]: epoch loss = 1.776883,   acc = 0.915093\n",
      "[epoch 29]: epoch loss = 1.697262,   acc = 0.918922\n",
      "[epoch 30]: epoch loss = 1.661534,   acc = 0.922270\n",
      "[epoch 31]: epoch loss = 1.604186,   acc = 0.926687\n",
      "[epoch 32]: epoch loss = 1.567685,   acc = 0.929277\n",
      "[epoch 33]: epoch loss = 1.521303,   acc = 0.936135\n",
      "[epoch 34]: epoch loss = 1.474699,   acc = 0.937643\n",
      "[epoch 35]: epoch loss = 1.456895,   acc = 0.937390\n",
      "[epoch 36]: epoch loss = 1.427471,   acc = 0.943909\n",
      "[epoch 37]: epoch loss = 1.379730,   acc = 0.949803\n",
      "[epoch 38]: epoch loss = 1.324519,   acc = 0.955253\n",
      "[epoch 39]: epoch loss = 1.292516,   acc = 0.959116\n",
      "[epoch 40]: epoch loss = 1.268232,   acc = 0.962931\n",
      "[epoch 41]: epoch loss = 1.251963,   acc = 0.963782\n",
      "[epoch 42]: epoch loss = 1.248212,   acc = 0.964810\n",
      "[epoch 43]: epoch loss = 1.198456,   acc = 0.967740\n",
      "[epoch 44]: epoch loss = 1.171484,   acc = 0.967187\n",
      "[epoch 45]: epoch loss = 1.214976,   acc = 0.962757\n",
      "[epoch 46]: epoch loss = 1.147760,   acc = 0.968691\n",
      "[epoch 47]: epoch loss = 1.133245,   acc = 0.969402\n",
      "[epoch 48]: epoch loss = 1.453366,   acc = 0.947253\n",
      "[epoch 49]: epoch loss = 2.179264,   acc = 0.892443\n",
      "[epoch 50]: epoch loss = 2.582220,   acc = 0.847095\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/main.py' --action='train' --dataset='50salads' --split='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f2fe7b2-fe80-4130-82d6-cb578a4955f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Start predicting\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/main.py' --action='predict' --dataset='50salads' --split='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b54de438-b500-43ca-8641-cef322aa66e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-tcn/eval.py:39: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  D = np.zeros([m_row+1, n_col+1], np.float)\n",
      "Acc: 68.6997\n",
      "Edit: 50.1300\n",
      "F1@0.10: 58.5895\n",
      "F1@0.25: 54.2495\n",
      "F1@0.50: 44.4846\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/eval.py' --dataset='50salads' --split='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09b3d619-d1c8-432c-8248-8bb376e2bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Start training\n",
      "[epoch 1]: epoch loss = 10.908585,   acc = 0.112970\n",
      "[epoch 2]: epoch loss = 9.112479,   acc = 0.205877\n",
      "[epoch 3]: epoch loss = 7.791645,   acc = 0.265613\n",
      "[epoch 4]: epoch loss = 6.762111,   acc = 0.344294\n",
      "[epoch 5]: epoch loss = 6.224672,   acc = 0.444120\n",
      "[epoch 6]: epoch loss = 5.045456,   acc = 0.550097\n",
      "[epoch 7]: epoch loss = 4.564454,   acc = 0.618658\n",
      "[epoch 8]: epoch loss = 4.435592,   acc = 0.677380\n",
      "[epoch 9]: epoch loss = 4.103742,   acc = 0.692252\n",
      "[epoch 10]: epoch loss = 3.988271,   acc = 0.712076\n",
      "[epoch 11]: epoch loss = 3.571268,   acc = 0.772185\n",
      "[epoch 12]: epoch loss = 3.188834,   acc = 0.805426\n",
      "[epoch 13]: epoch loss = 3.227580,   acc = 0.800249\n",
      "[epoch 14]: epoch loss = 3.165295,   acc = 0.800885\n",
      "[epoch 15]: epoch loss = 3.267592,   acc = 0.796319\n",
      "[epoch 16]: epoch loss = 2.889875,   acc = 0.827190\n",
      "[epoch 17]: epoch loss = 2.902713,   acc = 0.833502\n",
      "[epoch 18]: epoch loss = 2.552028,   acc = 0.859391\n",
      "[epoch 19]: epoch loss = 2.355151,   acc = 0.872973\n",
      "[epoch 20]: epoch loss = 2.226074,   acc = 0.880584\n",
      "[epoch 21]: epoch loss = 2.165249,   acc = 0.886350\n",
      "[epoch 22]: epoch loss = 3.371619,   acc = 0.794825\n",
      "[epoch 23]: epoch loss = 2.525740,   acc = 0.856692\n",
      "[epoch 24]: epoch loss = 2.363845,   acc = 0.868030\n",
      "[epoch 25]: epoch loss = 1.984125,   acc = 0.898688\n",
      "[epoch 26]: epoch loss = 1.855103,   acc = 0.907768\n",
      "[epoch 27]: epoch loss = 1.828324,   acc = 0.908942\n",
      "[epoch 28]: epoch loss = 1.760545,   acc = 0.912586\n",
      "[epoch 29]: epoch loss = 1.702412,   acc = 0.915250\n",
      "[epoch 30]: epoch loss = 1.690268,   acc = 0.917797\n",
      "[epoch 31]: epoch loss = 1.610900,   acc = 0.922935\n",
      "[epoch 32]: epoch loss = 1.555060,   acc = 0.930330\n",
      "[epoch 33]: epoch loss = 1.525620,   acc = 0.936426\n",
      "[epoch 34]: epoch loss = 1.547998,   acc = 0.934888\n",
      "[epoch 35]: epoch loss = 1.501732,   acc = 0.940719\n",
      "[epoch 36]: epoch loss = 1.389130,   acc = 0.952251\n",
      "[epoch 37]: epoch loss = 1.451600,   acc = 0.945463\n",
      "[epoch 38]: epoch loss = 1.511294,   acc = 0.937496\n",
      "[epoch 39]: epoch loss = 1.370584,   acc = 0.949964\n",
      "[epoch 40]: epoch loss = 1.281151,   acc = 0.959941\n",
      "[epoch 41]: epoch loss = 1.234748,   acc = 0.962462\n",
      "[epoch 42]: epoch loss = 1.201137,   acc = 0.963450\n",
      "[epoch 43]: epoch loss = 1.174667,   acc = 0.966538\n",
      "[epoch 44]: epoch loss = 1.171851,   acc = 0.963151\n",
      "[epoch 45]: epoch loss = 1.131587,   acc = 0.968046\n",
      "[epoch 46]: epoch loss = 1.247694,   acc = 0.956800\n",
      "[epoch 47]: epoch loss = 1.331572,   acc = 0.942460\n",
      "[epoch 48]: epoch loss = 1.386707,   acc = 0.946585\n",
      "[epoch 49]: epoch loss = 3.908881,   acc = 0.749411\n",
      "[epoch 50]: epoch loss = 3.548036,   acc = 0.783449\n",
      "Finish training\n",
      "Device is cuda\n",
      "Start predicting\n",
      "Finish predicting\n",
      "ms-tcn/eval.py:39: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  D = np.zeros([m_row+1, n_col+1], np.float)\n",
      "Acc: 74.0951\n",
      "Edit: 57.0170\n",
      "F1@0.10: 63.8889\n",
      "F1@0.25: 59.5238\n",
      "F1@0.50: 51.1905\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/main.py' --action='train' --dataset='50salads' --split='2'\n",
    "!python 'ms-tcn/main.py' --action='predict' --dataset='50salads' --split='2'\n",
    "!python 'ms-tcn/eval.py' --dataset='50salads' --split='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d186c1bc-06f0-429b-bfd6-b7f8deb82828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Start training\n",
      "[epoch 1]: epoch loss = 10.951506,   acc = 0.119185\n",
      "[epoch 2]: epoch loss = 9.064983,   acc = 0.209606\n",
      "[epoch 3]: epoch loss = 7.581831,   acc = 0.264956\n",
      "[epoch 4]: epoch loss = 6.462522,   acc = 0.400375\n",
      "[epoch 5]: epoch loss = 5.683653,   acc = 0.496809\n",
      "[epoch 6]: epoch loss = 6.177187,   acc = 0.485560\n",
      "[epoch 7]: epoch loss = 4.818046,   acc = 0.593829\n",
      "[epoch 8]: epoch loss = 4.338142,   acc = 0.648480\n",
      "[epoch 9]: epoch loss = 4.283604,   acc = 0.688866\n",
      "[epoch 10]: epoch loss = 3.958363,   acc = 0.689192\n",
      "[epoch 11]: epoch loss = 4.002500,   acc = 0.726832\n",
      "[epoch 12]: epoch loss = 3.509893,   acc = 0.777565\n",
      "[epoch 13]: epoch loss = 3.444819,   acc = 0.769353\n",
      "[epoch 14]: epoch loss = 3.000193,   acc = 0.826307\n",
      "[epoch 15]: epoch loss = 2.746903,   acc = 0.844958\n",
      "[epoch 16]: epoch loss = 2.660235,   acc = 0.849639\n",
      "[epoch 17]: epoch loss = 2.731286,   acc = 0.842811\n",
      "[epoch 18]: epoch loss = 2.387313,   acc = 0.875913\n",
      "[epoch 19]: epoch loss = 2.343057,   acc = 0.877765\n",
      "[epoch 20]: epoch loss = 2.262142,   acc = 0.878546\n",
      "[epoch 21]: epoch loss = 2.107566,   acc = 0.893401\n",
      "[epoch 22]: epoch loss = 2.036653,   acc = 0.899895\n",
      "[epoch 23]: epoch loss = 2.344376,   acc = 0.876299\n",
      "[epoch 24]: epoch loss = 3.245842,   acc = 0.790151\n",
      "[epoch 25]: epoch loss = 2.505306,   acc = 0.863557\n",
      "[epoch 26]: epoch loss = 2.831342,   acc = 0.826863\n",
      "[epoch 27]: epoch loss = 2.136371,   acc = 0.894347\n",
      "[epoch 28]: epoch loss = 2.045570,   acc = 0.896355\n",
      "[epoch 29]: epoch loss = 1.780225,   acc = 0.916620\n",
      "[epoch 30]: epoch loss = 1.709505,   acc = 0.923418\n",
      "[epoch 31]: epoch loss = 1.640894,   acc = 0.927310\n",
      "[epoch 32]: epoch loss = 1.583241,   acc = 0.933128\n",
      "[epoch 33]: epoch loss = 1.565858,   acc = 0.935388\n",
      "[epoch 34]: epoch loss = 1.561365,   acc = 0.936989\n",
      "[epoch 35]: epoch loss = 1.538870,   acc = 0.932251\n",
      "[epoch 36]: epoch loss = 1.440353,   acc = 0.945874\n",
      "[epoch 37]: epoch loss = 1.444295,   acc = 0.944959\n",
      "[epoch 38]: epoch loss = 1.398282,   acc = 0.952208\n",
      "[epoch 39]: epoch loss = 1.346426,   acc = 0.955332\n",
      "[epoch 40]: epoch loss = 1.291844,   acc = 0.961262\n",
      "[epoch 41]: epoch loss = 1.279363,   acc = 0.963167\n",
      "[epoch 42]: epoch loss = 1.818016,   acc = 0.925609\n",
      "[epoch 43]: epoch loss = 1.772451,   acc = 0.927765\n",
      "[epoch 44]: epoch loss = 2.900238,   acc = 0.841869\n",
      "[epoch 45]: epoch loss = 2.304567,   acc = 0.887340\n",
      "[epoch 46]: epoch loss = 1.553706,   acc = 0.948373\n",
      "[epoch 47]: epoch loss = 1.325848,   acc = 0.962807\n",
      "[epoch 48]: epoch loss = 1.233065,   acc = 0.969301\n",
      "[epoch 49]: epoch loss = 1.168547,   acc = 0.973501\n",
      "[epoch 50]: epoch loss = 1.124745,   acc = 0.975996\n",
      "Finish training\n",
      "Device is cuda\n",
      "Start predicting\n",
      "Finish predicting\n",
      "ms-tcn/eval.py:39: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  D = np.zeros([m_row+1, n_col+1], np.float)\n",
      "Acc: 80.2771\n",
      "Edit: 60.7139\n",
      "F1@0.10: 69.3227\n",
      "F1@0.25: 67.7291\n",
      "F1@0.50: 59.3625\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/main.py' --action='train' --dataset='50salads' --split='3'\n",
    "!python 'ms-tcn/main.py' --action='predict' --dataset='50salads' --split='3'\n",
    "!python 'ms-tcn/eval.py' --dataset='50salads' --split='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2186af42-af61-4c10-90c8-8f2ce467ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Start training\n",
      "[epoch 1]: epoch loss = 10.977026,   acc = 0.117110\n",
      "[epoch 2]: epoch loss = 9.189288,   acc = 0.201252\n",
      "[epoch 3]: epoch loss = 7.662015,   acc = 0.252346\n",
      "[epoch 4]: epoch loss = 6.141435,   acc = 0.410554\n",
      "[epoch 5]: epoch loss = 5.382736,   acc = 0.526497\n",
      "[epoch 6]: epoch loss = 4.727355,   acc = 0.601398\n",
      "[epoch 7]: epoch loss = 4.553202,   acc = 0.630150\n",
      "[epoch 8]: epoch loss = 4.384459,   acc = 0.672349\n",
      "[epoch 9]: epoch loss = 4.883730,   acc = 0.671031\n",
      "[epoch 10]: epoch loss = 5.073135,   acc = 0.603675\n",
      "[epoch 11]: epoch loss = 3.808517,   acc = 0.733313\n",
      "[epoch 12]: epoch loss = 3.253520,   acc = 0.803219\n",
      "[epoch 13]: epoch loss = 2.901515,   acc = 0.833618\n",
      "[epoch 14]: epoch loss = 2.723439,   acc = 0.847044\n",
      "[epoch 15]: epoch loss = 2.722240,   acc = 0.845023\n",
      "[epoch 16]: epoch loss = 2.562100,   acc = 0.857192\n",
      "[epoch 17]: epoch loss = 2.786041,   acc = 0.834975\n",
      "[epoch 18]: epoch loss = 3.217241,   acc = 0.817334\n",
      "[epoch 19]: epoch loss = 4.320040,   acc = 0.738881\n",
      "[epoch 20]: epoch loss = 3.273589,   acc = 0.803240\n",
      "[epoch 21]: epoch loss = 2.564231,   acc = 0.861355\n",
      "[epoch 22]: epoch loss = 2.300800,   acc = 0.882062\n",
      "[epoch 23]: epoch loss = 2.112843,   acc = 0.894127\n",
      "[epoch 24]: epoch loss = 1.991573,   acc = 0.900337\n",
      "[epoch 25]: epoch loss = 1.930845,   acc = 0.906165\n",
      "[epoch 26]: epoch loss = 1.842147,   acc = 0.912778\n",
      "[epoch 27]: epoch loss = 1.805024,   acc = 0.913086\n",
      "[epoch 28]: epoch loss = 1.742657,   acc = 0.915770\n",
      "[epoch 29]: epoch loss = 1.673499,   acc = 0.921499\n",
      "[epoch 30]: epoch loss = 1.645581,   acc = 0.923550\n",
      "[epoch 31]: epoch loss = 1.600696,   acc = 0.930866\n",
      "[epoch 32]: epoch loss = 1.542847,   acc = 0.941582\n",
      "[epoch 33]: epoch loss = 1.508662,   acc = 0.942974\n",
      "[epoch 34]: epoch loss = 1.477749,   acc = 0.947241\n",
      "[epoch 35]: epoch loss = 1.422881,   acc = 0.952571\n",
      "[epoch 36]: epoch loss = 1.356802,   acc = 0.958308\n",
      "[epoch 37]: epoch loss = 1.338625,   acc = 0.955008\n",
      "[epoch 38]: epoch loss = 1.336496,   acc = 0.955155\n",
      "[epoch 39]: epoch loss = 1.359149,   acc = 0.954201\n",
      "[epoch 40]: epoch loss = 1.323592,   acc = 0.955285\n",
      "[epoch 41]: epoch loss = 1.309416,   acc = 0.955819\n",
      "[epoch 42]: epoch loss = 1.229330,   acc = 0.961144\n",
      "[epoch 43]: epoch loss = 1.181509,   acc = 0.965702\n",
      "[epoch 44]: epoch loss = 1.143831,   acc = 0.967545\n",
      "[epoch 45]: epoch loss = 1.116547,   acc = 0.968998\n",
      "[epoch 46]: epoch loss = 1.111312,   acc = 0.971201\n",
      "[epoch 47]: epoch loss = 1.367401,   acc = 0.950797\n",
      "[epoch 48]: epoch loss = 1.422611,   acc = 0.948299\n",
      "[epoch 49]: epoch loss = 1.221216,   acc = 0.962853\n",
      "[epoch 50]: epoch loss = 1.091826,   acc = 0.973052\n",
      "Finish training\n",
      "Device is cuda\n",
      "Start predicting\n",
      "Finish predicting\n",
      "ms-tcn/eval.py:39: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  D = np.zeros([m_row+1, n_col+1], np.float)\n",
      "Acc: 80.6088\n",
      "Edit: 65.1687\n",
      "F1@0.10: 67.3469\n",
      "F1@0.25: 64.4898\n",
      "F1@0.50: 60.4082\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/main.py' --action='train' --dataset='50salads' --split='4'\n",
    "!python 'ms-tcn/main.py' --action='predict' --dataset='50salads' --split='4'\n",
    "!python 'ms-tcn/eval.py' --dataset='50salads' --split='4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e85c2a8-ce0a-4551-afd1-6549b3449c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "Start training\n",
      "[epoch 1]: epoch loss = 10.932435,   acc = 0.122068\n",
      "[epoch 2]: epoch loss = 9.111105,   acc = 0.209230\n",
      "[epoch 3]: epoch loss = 8.388283,   acc = 0.222172\n",
      "[epoch 4]: epoch loss = 6.889058,   acc = 0.326448\n",
      "[epoch 5]: epoch loss = 5.978184,   acc = 0.457872\n",
      "[epoch 6]: epoch loss = 5.086287,   acc = 0.554959\n",
      "[epoch 7]: epoch loss = 5.105566,   acc = 0.561908\n",
      "[epoch 8]: epoch loss = 4.539053,   acc = 0.636333\n",
      "[epoch 9]: epoch loss = 4.128896,   acc = 0.693653\n",
      "[epoch 10]: epoch loss = 4.193591,   acc = 0.694286\n",
      "[epoch 11]: epoch loss = 3.507825,   acc = 0.777340\n",
      "[epoch 12]: epoch loss = 3.403848,   acc = 0.785427\n",
      "[epoch 13]: epoch loss = 3.925797,   acc = 0.743190\n",
      "[epoch 14]: epoch loss = 3.740123,   acc = 0.764463\n",
      "[epoch 15]: epoch loss = 3.006234,   acc = 0.823783\n",
      "[epoch 16]: epoch loss = 2.680611,   acc = 0.852218\n",
      "[epoch 17]: epoch loss = 2.518105,   acc = 0.867503\n",
      "[epoch 18]: epoch loss = 2.412957,   acc = 0.874226\n",
      "[epoch 19]: epoch loss = 2.394890,   acc = 0.872683\n",
      "[epoch 20]: epoch loss = 2.577644,   acc = 0.839888\n",
      "[epoch 21]: epoch loss = 2.349894,   acc = 0.870499\n",
      "[epoch 22]: epoch loss = 2.199788,   acc = 0.887894\n",
      "[epoch 23]: epoch loss = 2.081194,   acc = 0.895558\n",
      "[epoch 24]: epoch loss = 1.951694,   acc = 0.901717\n",
      "[epoch 25]: epoch loss = 2.118700,   acc = 0.889651\n",
      "[epoch 26]: epoch loss = 2.759249,   acc = 0.832532\n",
      "[epoch 27]: epoch loss = 3.274751,   acc = 0.803297\n",
      "[epoch 28]: epoch loss = 2.174031,   acc = 0.882723\n",
      "[epoch 29]: epoch loss = 2.063307,   acc = 0.891331\n",
      "[epoch 30]: epoch loss = 1.992883,   acc = 0.896400\n",
      "[epoch 31]: epoch loss = 1.804500,   acc = 0.912398\n",
      "[epoch 32]: epoch loss = 1.683075,   acc = 0.921185\n",
      "[epoch 33]: epoch loss = 1.610685,   acc = 0.928439\n",
      "[epoch 34]: epoch loss = 1.545928,   acc = 0.938560\n",
      "[epoch 35]: epoch loss = 1.522962,   acc = 0.939474\n",
      "[epoch 36]: epoch loss = 1.467924,   acc = 0.946274\n",
      "[epoch 37]: epoch loss = 1.438307,   acc = 0.946937\n",
      "[epoch 38]: epoch loss = 1.387791,   acc = 0.951950\n",
      "[epoch 39]: epoch loss = 1.342621,   acc = 0.957909\n",
      "[epoch 40]: epoch loss = 1.326241,   acc = 0.956421\n",
      "[epoch 41]: epoch loss = 1.326148,   acc = 0.955588\n",
      "[epoch 42]: epoch loss = 1.302133,   acc = 0.958464\n",
      "[epoch 43]: epoch loss = 1.296134,   acc = 0.959157\n",
      "[epoch 44]: epoch loss = 1.235300,   acc = 0.963794\n",
      "[epoch 45]: epoch loss = 1.180080,   acc = 0.968213\n",
      "[epoch 46]: epoch loss = 1.157679,   acc = 0.970821\n",
      "[epoch 47]: epoch loss = 1.099029,   acc = 0.974813\n",
      "[epoch 48]: epoch loss = 1.069008,   acc = 0.977087\n",
      "[epoch 49]: epoch loss = 1.068462,   acc = 0.974753\n",
      "[epoch 50]: epoch loss = 1.075248,   acc = 0.974582\n",
      "Finish training\n",
      "Device is cuda\n",
      "Start predicting\n",
      "Finish predicting\n",
      "ms-tcn/eval.py:39: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  D = np.zeros([m_row+1, n_col+1], np.float)\n",
      "Acc: 84.5597\n",
      "Edit: 73.2029\n",
      "F1@0.10: 80.6846\n",
      "F1@0.25: 79.7066\n",
      "F1@0.50: 70.9046\n"
     ]
    }
   ],
   "source": [
    "!python 'ms-tcn/main.py' --action='train' --dataset='50salads' --split='5'\n",
    "!python 'ms-tcn/main.py' --action='predict' --dataset='50salads' --split='5'\n",
    "!python 'ms-tcn/eval.py' --dataset='50salads' --split='5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd734a-e649-424c-98c2-4f1b00aca494",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc: \n",
    "Edit: \n",
    "F1@0.10: \n",
    "F1@0.25: \n",
    "F1@0.50: \n",
    "\n",
    "Acc: \n",
    "Edit: \n",
    "F1@0.10: \n",
    "F1@0.25: \n",
    "F1@0.50: \n",
    "\n",
    "Acc: \n",
    "Edit: \n",
    "F1@0.10: \n",
    "F1@0.25: \n",
    "F1@0.50: \n",
    "\n",
    "Acc: \n",
    "Edit: \n",
    "F1@0.10: \n",
    "F1@0.25: \n",
    "F1@0.50: \n",
    "\n",
    "Acc: \n",
    "Edit: \n",
    "F1@0.10: \n",
    "F1@0.25: \n",
    "F1@0.50: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8143d8d8-4131-4446-b41b-ac30db4766b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.64808000000001"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 84.5597 + 80.6088 + 80.2771 + 74.0951 + 68.6997\n",
    "m / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08c6702b-4d39-479f-bff9-125889920c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "sys.path.append('/home/jupyter/ms-tcn/')\n",
    "\n",
    "from model import Trainer\n",
    "from batch_gen import BatchGenerator\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--action', default='train')\n",
    "# parser.add_argument('--dataset', default=\"gtea\")\n",
    "# parser.add_argument('--split', default='1')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "action = 'train'\n",
    "dataset = '50salads'\n",
    "split = '1'\n",
    "\n",
    "vid_list_file = \"./data/\"+dataset+\"/splits/train.split\"+split+\".bundle\"\n",
    "vid_list_file_tst = \"./data/\"+dataset+\"/splits/test.split\"+split+\".bundle\"\n",
    "features_path = \"./data/\"+dataset+\"/features/\"\n",
    "gt_path = \"./data/\"+dataset+\"/groundTruth/\"\n",
    "\n",
    "mapping_file = \"./data/\"+dataset+\"/mapping.txt\"\n",
    "\n",
    "model_dir = \"./models/\"+dataset+\"/split_\"+split\n",
    "results_dir = \"./results/\"+dataset+\"/split_\"+split\n",
    " \n",
    "num_stages = 4\n",
    "num_layers = 10\n",
    "num_f_maps = 64\n",
    "features_dim = 2048\n",
    "bz = 1\n",
    "lr = 0.0005\n",
    "num_epochs = 50\n",
    "sample_rate = 1\n",
    "\n",
    "file_ptr = open(mapping_file, 'r')\n",
    "actions = file_ptr.read().split('\\n')[:-1]\n",
    "file_ptr.close()\n",
    "actions_dict = dict()\n",
    "for a in actions:\n",
    "    actions_dict[a.split()[1]] = int(a.split()[0])\n",
    "\n",
    "num_classes = len(actions_dict)\n",
    "\n",
    "trainer = Trainer(num_stages, num_layers, num_f_maps, features_dim, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd9eb3b8-f6a7-49ad-970a-97eb5e2f710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 1\n",
    "batch_gen = BatchGenerator(num_classes, actions_dict, gt_path, features_path, sample_rate)\n",
    "batch_gen.read_data(vid_list_file)\n",
    "\n",
    "batch = batch_gen.list_of_examples[batch_gen.index:batch_gen.index + batch_size]\n",
    "batch_gen.index += batch_size\n",
    "\n",
    "batch_input = []\n",
    "batch_target = []\n",
    "for vid in batch:\n",
    "    features = np.load(batch_gen.features_path + vid.split('.')[0] + '.npy')\n",
    "    file_ptr = open(batch_gen.gt_path + vid, 'r')\n",
    "    content = file_ptr.read().split('\\n')[:-1]\n",
    "    classes = np.zeros(min(np.shape(features)[1], len(content)))\n",
    "    for i in range(len(classes)):\n",
    "        classes[i] = batch_gen.actions_dict[content[i]]\n",
    "    batch_input .append(features[:, ::batch_gen.sample_rate])\n",
    "    batch_target.append(classes[::batch_gen.sample_rate])\n",
    "\n",
    "length_of_sequences = list(map(len, batch_target))\n",
    "batch_input_tensor = torch.zeros(len(batch_input), np.shape(batch_input[0])[0], max(length_of_sequences), dtype=torch.float)\n",
    "batch_target_tensor = torch.ones(len(batch_input), max(length_of_sequences), dtype=torch.long)*(-100)\n",
    "mask = torch.zeros(len(batch_input), batch_gen.num_classes, max(length_of_sequences), dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76cbb9bd-7e3c-4b72-819c-22997197f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8364]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_of_sequences"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
